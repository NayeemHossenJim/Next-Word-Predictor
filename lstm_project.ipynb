{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "IrmA3eaj3kF0"
      },
      "outputs": [],
      "source": [
        "faqs = \"\"\"Who am I?\n",
        "I am an AI Engineer with a strong focus on building intelligent systems that solve real-world problems using modern machine learning and software engineering practices.\n",
        "\n",
        "What are my primary areas of interest?\n",
        "My key interests lie in Artificial Intelligence, Machine Learning systems, and Game Development. I am particularly passionate about designing systems that combine automation, reasoning, and real-time decision making.\n",
        "\n",
        "What kind of work do I enjoy doing the most?\n",
        "I enjoy working on backend AI infrastructure such as Retrieval-Augmented Generation (RAG) pipelines, embedding systems, vector databases, and production-ready ML deployments. I like solving problems related to model reliability, hallucination mitigation, retrieval optimization, and system scalability.\n",
        "\n",
        "Do I focus more on research or engineering?\n",
        "My focus is primarily on applied engineering — building production-grade systems that actually work in real environments rather than staying limited to theoretical implementations.\n",
        "\n",
        "What technologies do I typically work with?\n",
        "I frequently work with FastAPI, PostgreSQL, vector databases such as pgvector, and modern LLM-based architectures. I am also involved in system design for AI-driven platforms.\n",
        "\n",
        "Do I have an interest outside traditional AI applications?\n",
        "Yes. I am passionate about Game Development and enjoy exploring how AI can be integrated into interactive environments, simulations, and intelligent gameplay systems.\n",
        "\n",
        "What kind of problems motivate me?\n",
        "I am motivated by problems related to system performance, information retrieval, automation, and intelligent decision-making systems — especially where model outputs must be accurate, explainable, and grounded in real data.\n",
        "\n",
        "What is my approach to learning new technologies?\n",
        "I prefer hands-on experimentation and building real projects. I focus on understanding how systems behave under production constraints rather than limiting myself to tutorials or theoretical study.\n",
        "\n",
        "Do I work on scalable systems?\n",
        "Yes. I am interested in optimizing performance for AI pipelines, improving retrieval latency, handling embedding mismatches, and deploying scalable backend architectures.\n",
        "\n",
        "Am I interested in future-oriented technologies?\n",
        "Absolutely. I am keen on exploring advanced AI applications including autonomous agents, intelligent game environments, and real-time AI-assisted platforms.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "J1D42emD32Ro"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "KhtDxwL_AXFj"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "K8MRFre9AaG9"
      },
      "outputs": [],
      "source": [
        "tokenizer.fit_on_texts([faqs])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrpAl3EDAgvh",
        "outputId": "b8d7232a-c538-4f48-e331-aebea747c2c4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "177"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(tokenizer.word_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "44VahqKdAjr9"
      },
      "outputs": [],
      "source": [
        "input_sequences = []\n",
        "for sentence in faqs.split('\\n'):\n",
        "  tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0]\n",
        "\n",
        "  for i in range(1,len(tokenized_sentence)):\n",
        "    input_sequences.append(tokenized_sentence[:i+1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyqwPDzNA5mR",
        "outputId": "cf7f38c7-9ebe-475e-e51c-dfee031c80f0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[68, 3],\n",
              " [68, 3, 1],\n",
              " [1, 3],\n",
              " [1, 3, 30],\n",
              " [1, 3, 30, 5],\n",
              " [1, 3, 30, 5, 69],\n",
              " [1, 3, 30, 5, 69, 18],\n",
              " [1, 3, 30, 5, 69, 18, 70],\n",
              " [1, 3, 30, 5, 69, 18, 70, 71],\n",
              " [1, 3, 30, 5, 69, 18, 70, 71, 13],\n",
              " [1, 3, 30, 5, 69, 18, 70, 71, 13, 6],\n",
              " [1, 3, 30, 5, 69, 18, 70, 71, 13, 6, 19],\n",
              " [1, 3, 30, 5, 69, 18, 70, 71, 13, 6, 19, 14],\n",
              " [1, 3, 30, 5, 69, 18, 70, 71, 13, 6, 19, 14, 4],\n",
              " [1, 3, 30, 5, 69, 18, 70, 71, 13, 6, 19, 14, 4, 20],\n",
              " [1, 3, 30, 5, 69, 18, 70, 71, 13, 6, 19, 14, 4, 20, 72],\n",
              " [1, 3, 30, 5, 69, 18, 70, 71, 13, 6, 19, 14, 4, 20, 72, 7],\n",
              " [1, 3, 30, 5, 69, 18, 70, 71, 13, 6, 19, 14, 4, 20, 72, 7, 73],\n",
              " [1, 3, 30, 5, 69, 18, 70, 71, 13, 6, 19, 14, 4, 20, 72, 7, 73, 15],\n",
              " [1, 3, 30, 5, 69, 18, 70, 71, 13, 6, 19, 14, 4, 20, 72, 7, 73, 15, 74],\n",
              " [1, 3, 30, 5, 69, 18, 70, 71, 13, 6, 19, 14, 4, 20, 72, 7, 73, 15, 74, 31],\n",
              " [1,\n",
              "  3,\n",
              "  30,\n",
              "  5,\n",
              "  69,\n",
              "  18,\n",
              "  70,\n",
              "  71,\n",
              "  13,\n",
              "  6,\n",
              "  19,\n",
              "  14,\n",
              "  4,\n",
              "  20,\n",
              "  72,\n",
              "  7,\n",
              "  73,\n",
              "  15,\n",
              "  74,\n",
              "  31,\n",
              "  32],\n",
              " [1,\n",
              "  3,\n",
              "  30,\n",
              "  5,\n",
              "  69,\n",
              "  18,\n",
              "  70,\n",
              "  71,\n",
              "  13,\n",
              "  6,\n",
              "  19,\n",
              "  14,\n",
              "  4,\n",
              "  20,\n",
              "  72,\n",
              "  7,\n",
              "  73,\n",
              "  15,\n",
              "  74,\n",
              "  31,\n",
              "  32,\n",
              "  21],\n",
              " [1,\n",
              "  3,\n",
              "  30,\n",
              "  5,\n",
              "  69,\n",
              "  18,\n",
              "  70,\n",
              "  71,\n",
              "  13,\n",
              "  6,\n",
              "  19,\n",
              "  14,\n",
              "  4,\n",
              "  20,\n",
              "  72,\n",
              "  7,\n",
              "  73,\n",
              "  15,\n",
              "  74,\n",
              "  31,\n",
              "  32,\n",
              "  21,\n",
              "  2],\n",
              " [1,\n",
              "  3,\n",
              "  30,\n",
              "  5,\n",
              "  69,\n",
              "  18,\n",
              "  70,\n",
              "  71,\n",
              "  13,\n",
              "  6,\n",
              "  19,\n",
              "  14,\n",
              "  4,\n",
              "  20,\n",
              "  72,\n",
              "  7,\n",
              "  73,\n",
              "  15,\n",
              "  74,\n",
              "  31,\n",
              "  32,\n",
              "  21,\n",
              "  2,\n",
              "  75],\n",
              " [1,\n",
              "  3,\n",
              "  30,\n",
              "  5,\n",
              "  69,\n",
              "  18,\n",
              "  70,\n",
              "  71,\n",
              "  13,\n",
              "  6,\n",
              "  19,\n",
              "  14,\n",
              "  4,\n",
              "  20,\n",
              "  72,\n",
              "  7,\n",
              "  73,\n",
              "  15,\n",
              "  74,\n",
              "  31,\n",
              "  32,\n",
              "  21,\n",
              "  2,\n",
              "  75,\n",
              "  22],\n",
              " [1,\n",
              "  3,\n",
              "  30,\n",
              "  5,\n",
              "  69,\n",
              "  18,\n",
              "  70,\n",
              "  71,\n",
              "  13,\n",
              "  6,\n",
              "  19,\n",
              "  14,\n",
              "  4,\n",
              "  20,\n",
              "  72,\n",
              "  7,\n",
              "  73,\n",
              "  15,\n",
              "  74,\n",
              "  31,\n",
              "  32,\n",
              "  21,\n",
              "  2,\n",
              "  75,\n",
              "  22,\n",
              "  76],\n",
              " [9, 77],\n",
              " [9, 77, 16],\n",
              " [9, 77, 16, 78],\n",
              " [9, 77, 16, 78, 79],\n",
              " [9, 77, 16, 78, 79, 23],\n",
              " [9, 77, 16, 78, 79, 23, 33],\n",
              " [16, 80],\n",
              " [16, 80, 81],\n",
              " [16, 80, 81, 82],\n",
              " [16, 80, 81, 82, 8],\n",
              " [16, 80, 81, 82, 8, 83],\n",
              " [16, 80, 81, 82, 8, 83, 84],\n",
              " [16, 80, 81, 82, 8, 83, 84, 32],\n",
              " [16, 80, 81, 82, 8, 83, 84, 32, 21],\n",
              " [16, 80, 81, 82, 8, 83, 84, 32, 21, 4],\n",
              " [16, 80, 81, 82, 8, 83, 84, 32, 21, 4, 2],\n",
              " [16, 80, 81, 82, 8, 83, 84, 32, 21, 4, 2, 24],\n",
              " [16, 80, 81, 82, 8, 83, 84, 32, 21, 4, 2, 24, 34],\n",
              " [16, 80, 81, 82, 8, 83, 84, 32, 21, 4, 2, 24, 34, 1],\n",
              " [16, 80, 81, 82, 8, 83, 84, 32, 21, 4, 2, 24, 34, 1, 3],\n",
              " [16, 80, 81, 82, 8, 83, 84, 32, 21, 4, 2, 24, 34, 1, 3, 85],\n",
              " [16, 80, 81, 82, 8, 83, 84, 32, 21, 4, 2, 24, 34, 1, 3, 85, 35],\n",
              " [16, 80, 81, 82, 8, 83, 84, 32, 21, 4, 2, 24, 34, 1, 3, 85, 35, 36],\n",
              " [16, 80, 81, 82, 8, 83, 84, 32, 21, 4, 2, 24, 34, 1, 3, 85, 35, 36, 86],\n",
              " [16, 80, 81, 82, 8, 83, 84, 32, 21, 4, 2, 24, 34, 1, 3, 85, 35, 36, 86, 4],\n",
              " [16,\n",
              "  80,\n",
              "  81,\n",
              "  82,\n",
              "  8,\n",
              "  83,\n",
              "  84,\n",
              "  32,\n",
              "  21,\n",
              "  4,\n",
              "  2,\n",
              "  24,\n",
              "  34,\n",
              "  1,\n",
              "  3,\n",
              "  85,\n",
              "  35,\n",
              "  36,\n",
              "  86,\n",
              "  4,\n",
              "  20],\n",
              " [16,\n",
              "  80,\n",
              "  81,\n",
              "  82,\n",
              "  8,\n",
              "  83,\n",
              "  84,\n",
              "  32,\n",
              "  21,\n",
              "  4,\n",
              "  2,\n",
              "  24,\n",
              "  34,\n",
              "  1,\n",
              "  3,\n",
              "  85,\n",
              "  35,\n",
              "  36,\n",
              "  86,\n",
              "  4,\n",
              "  20,\n",
              "  87],\n",
              " [16,\n",
              "  80,\n",
              "  81,\n",
              "  82,\n",
              "  8,\n",
              "  83,\n",
              "  84,\n",
              "  32,\n",
              "  21,\n",
              "  4,\n",
              "  2,\n",
              "  24,\n",
              "  34,\n",
              "  1,\n",
              "  3,\n",
              "  85,\n",
              "  35,\n",
              "  36,\n",
              "  86,\n",
              "  4,\n",
              "  20,\n",
              "  87,\n",
              "  37],\n",
              " [16,\n",
              "  80,\n",
              "  81,\n",
              "  82,\n",
              "  8,\n",
              "  83,\n",
              "  84,\n",
              "  32,\n",
              "  21,\n",
              "  4,\n",
              "  2,\n",
              "  24,\n",
              "  34,\n",
              "  1,\n",
              "  3,\n",
              "  85,\n",
              "  35,\n",
              "  36,\n",
              "  86,\n",
              "  4,\n",
              "  20,\n",
              "  87,\n",
              "  37,\n",
              "  88],\n",
              " [16,\n",
              "  80,\n",
              "  81,\n",
              "  82,\n",
              "  8,\n",
              "  83,\n",
              "  84,\n",
              "  32,\n",
              "  21,\n",
              "  4,\n",
              "  2,\n",
              "  24,\n",
              "  34,\n",
              "  1,\n",
              "  3,\n",
              "  85,\n",
              "  35,\n",
              "  36,\n",
              "  86,\n",
              "  4,\n",
              "  20,\n",
              "  87,\n",
              "  37,\n",
              "  88,\n",
              "  2],\n",
              " [16,\n",
              "  80,\n",
              "  81,\n",
              "  82,\n",
              "  8,\n",
              "  83,\n",
              "  84,\n",
              "  32,\n",
              "  21,\n",
              "  4,\n",
              "  2,\n",
              "  24,\n",
              "  34,\n",
              "  1,\n",
              "  3,\n",
              "  85,\n",
              "  35,\n",
              "  36,\n",
              "  86,\n",
              "  4,\n",
              "  20,\n",
              "  87,\n",
              "  37,\n",
              "  88,\n",
              "  2,\n",
              "  7],\n",
              " [16,\n",
              "  80,\n",
              "  81,\n",
              "  82,\n",
              "  8,\n",
              "  83,\n",
              "  84,\n",
              "  32,\n",
              "  21,\n",
              "  4,\n",
              "  2,\n",
              "  24,\n",
              "  34,\n",
              "  1,\n",
              "  3,\n",
              "  85,\n",
              "  35,\n",
              "  36,\n",
              "  86,\n",
              "  4,\n",
              "  20,\n",
              "  87,\n",
              "  37,\n",
              "  88,\n",
              "  2,\n",
              "  7,\n",
              "  38],\n",
              " [16,\n",
              "  80,\n",
              "  81,\n",
              "  82,\n",
              "  8,\n",
              "  83,\n",
              "  84,\n",
              "  32,\n",
              "  21,\n",
              "  4,\n",
              "  2,\n",
              "  24,\n",
              "  34,\n",
              "  1,\n",
              "  3,\n",
              "  85,\n",
              "  35,\n",
              "  36,\n",
              "  86,\n",
              "  4,\n",
              "  20,\n",
              "  87,\n",
              "  37,\n",
              "  88,\n",
              "  2,\n",
              "  7,\n",
              "  38,\n",
              "  39],\n",
              " [16,\n",
              "  80,\n",
              "  81,\n",
              "  82,\n",
              "  8,\n",
              "  83,\n",
              "  84,\n",
              "  32,\n",
              "  21,\n",
              "  4,\n",
              "  2,\n",
              "  24,\n",
              "  34,\n",
              "  1,\n",
              "  3,\n",
              "  85,\n",
              "  35,\n",
              "  36,\n",
              "  86,\n",
              "  4,\n",
              "  20,\n",
              "  87,\n",
              "  37,\n",
              "  88,\n",
              "  2,\n",
              "  7,\n",
              "  38,\n",
              "  39,\n",
              "  40],\n",
              " [9, 41],\n",
              " [9, 41, 23],\n",
              " [9, 41, 23, 10],\n",
              " [9, 41, 23, 10, 11],\n",
              " [9, 41, 23, 10, 11, 1],\n",
              " [9, 41, 23, 10, 11, 1, 25],\n",
              " [9, 41, 23, 10, 11, 1, 25, 89],\n",
              " [9, 41, 23, 10, 11, 1, 25, 89, 90],\n",
              " [9, 41, 23, 10, 11, 1, 25, 89, 90, 91],\n",
              " [1, 25],\n",
              " [1, 25, 92],\n",
              " [1, 25, 92, 6],\n",
              " [1, 25, 92, 6, 42],\n",
              " [1, 25, 92, 6, 42, 5],\n",
              " [1, 25, 92, 6, 42, 5, 93],\n",
              " [1, 25, 92, 6, 42, 5, 93, 43],\n",
              " [1, 25, 92, 6, 42, 5, 93, 43, 44],\n",
              " [1, 25, 92, 6, 42, 5, 93, 43, 44, 17],\n",
              " [1, 25, 92, 6, 42, 5, 93, 43, 44, 17, 94],\n",
              " [1, 25, 92, 6, 42, 5, 93, 43, 44, 17, 94, 95],\n",
              " [1, 25, 92, 6, 42, 5, 93, 43, 44, 17, 94, 95, 96],\n",
              " [1, 25, 92, 6, 42, 5, 93, 43, 44, 17, 94, 95, 96, 45],\n",
              " [1, 25, 92, 6, 42, 5, 93, 43, 44, 17, 94, 95, 96, 45, 46],\n",
              " [1, 25, 92, 6, 42, 5, 93, 43, 44, 17, 94, 95, 96, 45, 46, 4],\n",
              " [1, 25, 92, 6, 42, 5, 93, 43, 44, 17, 94, 95, 96, 45, 46, 4, 47],\n",
              " [1, 25, 92, 6, 42, 5, 93, 43, 44, 17, 94, 95, 96, 45, 46, 4, 47, 48],\n",
              " [1, 25, 92, 6, 42, 5, 93, 43, 44, 17, 94, 95, 96, 45, 46, 4, 47, 48, 2],\n",
              " [1, 25, 92, 6, 42, 5, 93, 43, 44, 17, 94, 95, 96, 45, 46, 4, 47, 48, 2, 26],\n",
              " [1,\n",
              "  25,\n",
              "  92,\n",
              "  6,\n",
              "  42,\n",
              "  5,\n",
              "  93,\n",
              "  43,\n",
              "  44,\n",
              "  17,\n",
              "  94,\n",
              "  95,\n",
              "  96,\n",
              "  45,\n",
              "  46,\n",
              "  4,\n",
              "  47,\n",
              "  48,\n",
              "  2,\n",
              "  26,\n",
              "  97],\n",
              " [1,\n",
              "  25,\n",
              "  92,\n",
              "  6,\n",
              "  42,\n",
              "  5,\n",
              "  93,\n",
              "  43,\n",
              "  44,\n",
              "  17,\n",
              "  94,\n",
              "  95,\n",
              "  96,\n",
              "  45,\n",
              "  46,\n",
              "  4,\n",
              "  47,\n",
              "  48,\n",
              "  2,\n",
              "  26,\n",
              "  97,\n",
              "  98],\n",
              " [1,\n",
              "  25,\n",
              "  92,\n",
              "  6,\n",
              "  42,\n",
              "  5,\n",
              "  93,\n",
              "  43,\n",
              "  44,\n",
              "  17,\n",
              "  94,\n",
              "  95,\n",
              "  96,\n",
              "  45,\n",
              "  46,\n",
              "  4,\n",
              "  47,\n",
              "  48,\n",
              "  2,\n",
              "  26,\n",
              "  97,\n",
              "  98,\n",
              "  99],\n",
              " [1,\n",
              "  25,\n",
              "  92,\n",
              "  6,\n",
              "  42,\n",
              "  5,\n",
              "  93,\n",
              "  43,\n",
              "  44,\n",
              "  17,\n",
              "  94,\n",
              "  95,\n",
              "  96,\n",
              "  45,\n",
              "  46,\n",
              "  4,\n",
              "  47,\n",
              "  48,\n",
              "  2,\n",
              "  26,\n",
              "  97,\n",
              "  98,\n",
              "  99,\n",
              "  1],\n",
              " [1,\n",
              "  25,\n",
              "  92,\n",
              "  6,\n",
              "  42,\n",
              "  5,\n",
              "  93,\n",
              "  43,\n",
              "  44,\n",
              "  17,\n",
              "  94,\n",
              "  95,\n",
              "  96,\n",
              "  45,\n",
              "  46,\n",
              "  4,\n",
              "  47,\n",
              "  48,\n",
              "  2,\n",
              "  26,\n",
              "  97,\n",
              "  98,\n",
              "  99,\n",
              "  1,\n",
              "  100],\n",
              " [1,\n",
              "  25,\n",
              "  92,\n",
              "  6,\n",
              "  42,\n",
              "  5,\n",
              "  93,\n",
              "  43,\n",
              "  44,\n",
              "  17,\n",
              "  94,\n",
              "  95,\n",
              "  96,\n",
              "  45,\n",
              "  46,\n",
              "  4,\n",
              "  47,\n",
              "  48,\n",
              "  2,\n",
              "  26,\n",
              "  97,\n",
              "  98,\n",
              "  99,\n",
              "  1,\n",
              "  100,\n",
              "  101],\n",
              " [1,\n",
              "  25,\n",
              "  92,\n",
              "  6,\n",
              "  42,\n",
              "  5,\n",
              "  93,\n",
              "  43,\n",
              "  44,\n",
              "  17,\n",
              "  94,\n",
              "  95,\n",
              "  96,\n",
              "  45,\n",
              "  46,\n",
              "  4,\n",
              "  47,\n",
              "  48,\n",
              "  2,\n",
              "  26,\n",
              "  97,\n",
              "  98,\n",
              "  99,\n",
              "  1,\n",
              "  100,\n",
              "  101,\n",
              "  15],\n",
              " [1,\n",
              "  25,\n",
              "  92,\n",
              "  6,\n",
              "  42,\n",
              "  5,\n",
              "  93,\n",
              "  43,\n",
              "  44,\n",
              "  17,\n",
              "  94,\n",
              "  95,\n",
              "  96,\n",
              "  45,\n",
              "  46,\n",
              "  4,\n",
              "  47,\n",
              "  48,\n",
              "  2,\n",
              "  26,\n",
              "  97,\n",
              "  98,\n",
              "  99,\n",
              "  1,\n",
              "  100,\n",
              "  101,\n",
              "  15,\n",
              "  49],\n",
              " [1,\n",
              "  25,\n",
              "  92,\n",
              "  6,\n",
              "  42,\n",
              "  5,\n",
              "  93,\n",
              "  43,\n",
              "  44,\n",
              "  17,\n",
              "  94,\n",
              "  95,\n",
              "  96,\n",
              "  45,\n",
              "  46,\n",
              "  4,\n",
              "  47,\n",
              "  48,\n",
              "  2,\n",
              "  26,\n",
              "  97,\n",
              "  98,\n",
              "  99,\n",
              "  1,\n",
              "  100,\n",
              "  101,\n",
              "  15,\n",
              "  49,\n",
              "  12],\n",
              " [1,\n",
              "  25,\n",
              "  92,\n",
              "  6,\n",
              "  42,\n",
              "  5,\n",
              "  93,\n",
              "  43,\n",
              "  44,\n",
              "  17,\n",
              "  94,\n",
              "  95,\n",
              "  96,\n",
              "  45,\n",
              "  46,\n",
              "  4,\n",
              "  47,\n",
              "  48,\n",
              "  2,\n",
              "  26,\n",
              "  97,\n",
              "  98,\n",
              "  99,\n",
              "  1,\n",
              "  100,\n",
              "  101,\n",
              "  15,\n",
              "  49,\n",
              "  12,\n",
              "  50],\n",
              " [1,\n",
              "  25,\n",
              "  92,\n",
              "  6,\n",
              "  42,\n",
              "  5,\n",
              "  93,\n",
              "  43,\n",
              "  44,\n",
              "  17,\n",
              "  94,\n",
              "  95,\n",
              "  96,\n",
              "  45,\n",
              "  46,\n",
              "  4,\n",
              "  47,\n",
              "  48,\n",
              "  2,\n",
              "  26,\n",
              "  97,\n",
              "  98,\n",
              "  99,\n",
              "  1,\n",
              "  100,\n",
              "  101,\n",
              "  15,\n",
              "  49,\n",
              "  12,\n",
              "  50,\n",
              "  102],\n",
              " [1,\n",
              "  25,\n",
              "  92,\n",
              "  6,\n",
              "  42,\n",
              "  5,\n",
              "  93,\n",
              "  43,\n",
              "  44,\n",
              "  17,\n",
              "  94,\n",
              "  95,\n",
              "  96,\n",
              "  45,\n",
              "  46,\n",
              "  4,\n",
              "  47,\n",
              "  48,\n",
              "  2,\n",
              "  26,\n",
              "  97,\n",
              "  98,\n",
              "  99,\n",
              "  1,\n",
              "  100,\n",
              "  101,\n",
              "  15,\n",
              "  49,\n",
              "  12,\n",
              "  50,\n",
              "  102,\n",
              "  103],\n",
              " [1,\n",
              "  25,\n",
              "  92,\n",
              "  6,\n",
              "  42,\n",
              "  5,\n",
              "  93,\n",
              "  43,\n",
              "  44,\n",
              "  17,\n",
              "  94,\n",
              "  95,\n",
              "  96,\n",
              "  45,\n",
              "  46,\n",
              "  4,\n",
              "  47,\n",
              "  48,\n",
              "  2,\n",
              "  26,\n",
              "  97,\n",
              "  98,\n",
              "  99,\n",
              "  1,\n",
              "  100,\n",
              "  101,\n",
              "  15,\n",
              "  49,\n",
              "  12,\n",
              "  50,\n",
              "  102,\n",
              "  103,\n",
              "  104],\n",
              " [1,\n",
              "  25,\n",
              "  92,\n",
              "  6,\n",
              "  42,\n",
              "  5,\n",
              "  93,\n",
              "  43,\n",
              "  44,\n",
              "  17,\n",
              "  94,\n",
              "  95,\n",
              "  96,\n",
              "  45,\n",
              "  46,\n",
              "  4,\n",
              "  47,\n",
              "  48,\n",
              "  2,\n",
              "  26,\n",
              "  97,\n",
              "  98,\n",
              "  99,\n",
              "  1,\n",
              "  100,\n",
              "  101,\n",
              "  15,\n",
              "  49,\n",
              "  12,\n",
              "  50,\n",
              "  102,\n",
              "  103,\n",
              "  104,\n",
              "  17],\n",
              " [1,\n",
              "  25,\n",
              "  92,\n",
              "  6,\n",
              "  42,\n",
              "  5,\n",
              "  93,\n",
              "  43,\n",
              "  44,\n",
              "  17,\n",
              "  94,\n",
              "  95,\n",
              "  96,\n",
              "  45,\n",
              "  46,\n",
              "  4,\n",
              "  47,\n",
              "  48,\n",
              "  2,\n",
              "  26,\n",
              "  97,\n",
              "  98,\n",
              "  99,\n",
              "  1,\n",
              "  100,\n",
              "  101,\n",
              "  15,\n",
              "  49,\n",
              "  12,\n",
              "  50,\n",
              "  102,\n",
              "  103,\n",
              "  104,\n",
              "  17,\n",
              "  105],\n",
              " [1,\n",
              "  25,\n",
              "  92,\n",
              "  6,\n",
              "  42,\n",
              "  5,\n",
              "  93,\n",
              "  43,\n",
              "  44,\n",
              "  17,\n",
              "  94,\n",
              "  95,\n",
              "  96,\n",
              "  45,\n",
              "  46,\n",
              "  4,\n",
              "  47,\n",
              "  48,\n",
              "  2,\n",
              "  26,\n",
              "  97,\n",
              "  98,\n",
              "  99,\n",
              "  1,\n",
              "  100,\n",
              "  101,\n",
              "  15,\n",
              "  49,\n",
              "  12,\n",
              "  50,\n",
              "  102,\n",
              "  103,\n",
              "  104,\n",
              "  17,\n",
              "  105,\n",
              "  2],\n",
              " [1,\n",
              "  25,\n",
              "  92,\n",
              "  6,\n",
              "  42,\n",
              "  5,\n",
              "  93,\n",
              "  43,\n",
              "  44,\n",
              "  17,\n",
              "  94,\n",
              "  95,\n",
              "  96,\n",
              "  45,\n",
              "  46,\n",
              "  4,\n",
              "  47,\n",
              "  48,\n",
              "  2,\n",
              "  26,\n",
              "  97,\n",
              "  98,\n",
              "  99,\n",
              "  1,\n",
              "  100,\n",
              "  101,\n",
              "  15,\n",
              "  49,\n",
              "  12,\n",
              "  50,\n",
              "  102,\n",
              "  103,\n",
              "  104,\n",
              "  17,\n",
              "  105,\n",
              "  2,\n",
              "  27],\n",
              " [1,\n",
              "  25,\n",
              "  92,\n",
              "  6,\n",
              "  42,\n",
              "  5,\n",
              "  93,\n",
              "  43,\n",
              "  44,\n",
              "  17,\n",
              "  94,\n",
              "  95,\n",
              "  96,\n",
              "  45,\n",
              "  46,\n",
              "  4,\n",
              "  47,\n",
              "  48,\n",
              "  2,\n",
              "  26,\n",
              "  97,\n",
              "  98,\n",
              "  99,\n",
              "  1,\n",
              "  100,\n",
              "  101,\n",
              "  15,\n",
              "  49,\n",
              "  12,\n",
              "  50,\n",
              "  102,\n",
              "  103,\n",
              "  104,\n",
              "  17,\n",
              "  105,\n",
              "  2,\n",
              "  27,\n",
              "  106],\n",
              " [11, 1],\n",
              " [11, 1, 13],\n",
              " [11, 1, 13, 107],\n",
              " [11, 1, 13, 107, 6],\n",
              " [11, 1, 13, 107, 6, 108],\n",
              " [11, 1, 13, 107, 6, 108, 51],\n",
              " [11, 1, 13, 107, 6, 108, 51, 22],\n",
              " [16, 13],\n",
              " [16, 13, 52],\n",
              " [16, 13, 52, 109],\n",
              " [16, 13, 52, 109, 6],\n",
              " [16, 13, 52, 109, 6, 110],\n",
              " [16, 13, 52, 109, 6, 110, 22],\n",
              " [16, 13, 52, 109, 6, 110, 22, 53],\n",
              " [16, 13, 52, 109, 6, 110, 22, 53, 19],\n",
              " [16, 13, 52, 109, 6, 110, 22, 53, 19, 26],\n",
              " [16, 13, 52, 109, 6, 110, 22, 53, 19, 26, 111],\n",
              " [16, 13, 52, 109, 6, 110, 22, 53, 19, 26, 111, 4],\n",
              " [16, 13, 52, 109, 6, 110, 22, 53, 19, 26, 111, 4, 20],\n",
              " [16, 13, 52, 109, 6, 110, 22, 53, 19, 26, 111, 4, 20, 112],\n",
              " [16, 13, 52, 109, 6, 110, 22, 53, 19, 26, 111, 4, 20, 112, 10],\n",
              " [16, 13, 52, 109, 6, 110, 22, 53, 19, 26, 111, 4, 20, 112, 10, 8],\n",
              " [16, 13, 52, 109, 6, 110, 22, 53, 19, 26, 111, 4, 20, 112, 10, 8, 7],\n",
              " [16, 13, 52, 109, 6, 110, 22, 53, 19, 26, 111, 4, 20, 112, 10, 8, 7, 28],\n",
              " [16, 13, 52, 109, 6, 110, 22, 53, 19, 26, 111, 4, 20, 112, 10, 8, 7, 28, 54],\n",
              " [16,\n",
              "  13,\n",
              "  52,\n",
              "  109,\n",
              "  6,\n",
              "  110,\n",
              "  22,\n",
              "  53,\n",
              "  19,\n",
              "  26,\n",
              "  111,\n",
              "  4,\n",
              "  20,\n",
              "  112,\n",
              "  10,\n",
              "  8,\n",
              "  7,\n",
              "  28,\n",
              "  54,\n",
              "  55],\n",
              " [16,\n",
              "  13,\n",
              "  52,\n",
              "  109,\n",
              "  6,\n",
              "  110,\n",
              "  22,\n",
              "  53,\n",
              "  19,\n",
              "  26,\n",
              "  111,\n",
              "  4,\n",
              "  20,\n",
              "  112,\n",
              "  10,\n",
              "  8,\n",
              "  7,\n",
              "  28,\n",
              "  54,\n",
              "  55,\n",
              "  113],\n",
              " [16,\n",
              "  13,\n",
              "  52,\n",
              "  109,\n",
              "  6,\n",
              "  110,\n",
              "  22,\n",
              "  53,\n",
              "  19,\n",
              "  26,\n",
              "  111,\n",
              "  4,\n",
              "  20,\n",
              "  112,\n",
              "  10,\n",
              "  8,\n",
              "  7,\n",
              "  28,\n",
              "  54,\n",
              "  55,\n",
              "  113,\n",
              "  114],\n",
              " [16,\n",
              "  13,\n",
              "  52,\n",
              "  109,\n",
              "  6,\n",
              "  110,\n",
              "  22,\n",
              "  53,\n",
              "  19,\n",
              "  26,\n",
              "  111,\n",
              "  4,\n",
              "  20,\n",
              "  112,\n",
              "  10,\n",
              "  8,\n",
              "  7,\n",
              "  28,\n",
              "  54,\n",
              "  55,\n",
              "  113,\n",
              "  114,\n",
              "  12],\n",
              " [16,\n",
              "  13,\n",
              "  52,\n",
              "  109,\n",
              "  6,\n",
              "  110,\n",
              "  22,\n",
              "  53,\n",
              "  19,\n",
              "  26,\n",
              "  111,\n",
              "  4,\n",
              "  20,\n",
              "  112,\n",
              "  10,\n",
              "  8,\n",
              "  7,\n",
              "  28,\n",
              "  54,\n",
              "  55,\n",
              "  113,\n",
              "  114,\n",
              "  12,\n",
              "  56],\n",
              " [16,\n",
              "  13,\n",
              "  52,\n",
              "  109,\n",
              "  6,\n",
              "  110,\n",
              "  22,\n",
              "  53,\n",
              "  19,\n",
              "  26,\n",
              "  111,\n",
              "  4,\n",
              "  20,\n",
              "  112,\n",
              "  10,\n",
              "  8,\n",
              "  7,\n",
              "  28,\n",
              "  54,\n",
              "  55,\n",
              "  113,\n",
              "  114,\n",
              "  12,\n",
              "  56,\n",
              "  115],\n",
              " [9, 29],\n",
              " [9, 29, 11],\n",
              " [9, 29, 11, 1],\n",
              " [9, 29, 11, 1, 116],\n",
              " [9, 29, 11, 1, 116, 10],\n",
              " [9, 29, 11, 1, 116, 10, 18],\n",
              " [1, 117],\n",
              " [1, 117, 10],\n",
              " [1, 117, 10, 18],\n",
              " [1, 117, 10, 18, 118],\n",
              " [1, 117, 10, 18, 118, 119],\n",
              " [1, 117, 10, 18, 118, 119, 47],\n",
              " [1, 117, 10, 18, 118, 119, 47, 48],\n",
              " [1, 117, 10, 18, 118, 119, 47, 48, 43],\n",
              " [1, 117, 10, 18, 118, 119, 47, 48, 43, 44],\n",
              " [1, 117, 10, 18, 118, 119, 47, 48, 43, 44, 120],\n",
              " [1, 117, 10, 18, 118, 119, 47, 48, 43, 44, 120, 2],\n",
              " [1, 117, 10, 18, 118, 119, 47, 48, 43, 44, 120, 2, 31],\n",
              " [1, 117, 10, 18, 118, 119, 47, 48, 43, 44, 120, 2, 31, 121],\n",
              " [1, 117, 10, 18, 118, 119, 47, 48, 43, 44, 120, 2, 31, 121, 122],\n",
              " [1, 117, 10, 18, 118, 119, 47, 48, 43, 44, 120, 2, 31, 121, 122, 57],\n",
              " [1, 117, 10, 18, 118, 119, 47, 48, 43, 44, 120, 2, 31, 121, 122, 57, 1],\n",
              " [1, 117, 10, 18, 118, 119, 47, 48, 43, 44, 120, 2, 31, 121, 122, 57, 1, 3],\n",
              " [1,\n",
              "  117,\n",
              "  10,\n",
              "  18,\n",
              "  118,\n",
              "  119,\n",
              "  47,\n",
              "  48,\n",
              "  43,\n",
              "  44,\n",
              "  120,\n",
              "  2,\n",
              "  31,\n",
              "  121,\n",
              "  122,\n",
              "  57,\n",
              "  1,\n",
              "  3,\n",
              "  123],\n",
              " [1,\n",
              "  117,\n",
              "  10,\n",
              "  18,\n",
              "  118,\n",
              "  119,\n",
              "  47,\n",
              "  48,\n",
              "  43,\n",
              "  44,\n",
              "  120,\n",
              "  2,\n",
              "  31,\n",
              "  121,\n",
              "  122,\n",
              "  57,\n",
              "  1,\n",
              "  3,\n",
              "  123,\n",
              "  124],\n",
              " [1,\n",
              "  117,\n",
              "  10,\n",
              "  18,\n",
              "  118,\n",
              "  119,\n",
              "  47,\n",
              "  48,\n",
              "  43,\n",
              "  44,\n",
              "  120,\n",
              "  2,\n",
              "  31,\n",
              "  121,\n",
              "  122,\n",
              "  57,\n",
              "  1,\n",
              "  3,\n",
              "  123,\n",
              "  124,\n",
              "  8],\n",
              " [1,\n",
              "  117,\n",
              "  10,\n",
              "  18,\n",
              "  118,\n",
              "  119,\n",
              "  47,\n",
              "  48,\n",
              "  43,\n",
              "  44,\n",
              "  120,\n",
              "  2,\n",
              "  31,\n",
              "  121,\n",
              "  122,\n",
              "  57,\n",
              "  1,\n",
              "  3,\n",
              "  123,\n",
              "  124,\n",
              "  8,\n",
              "  27],\n",
              " [1,\n",
              "  117,\n",
              "  10,\n",
              "  18,\n",
              "  118,\n",
              "  119,\n",
              "  47,\n",
              "  48,\n",
              "  43,\n",
              "  44,\n",
              "  120,\n",
              "  2,\n",
              "  31,\n",
              "  121,\n",
              "  122,\n",
              "  57,\n",
              "  1,\n",
              "  3,\n",
              "  123,\n",
              "  124,\n",
              "  8,\n",
              "  27,\n",
              "  125],\n",
              " [1,\n",
              "  117,\n",
              "  10,\n",
              "  18,\n",
              "  118,\n",
              "  119,\n",
              "  47,\n",
              "  48,\n",
              "  43,\n",
              "  44,\n",
              "  120,\n",
              "  2,\n",
              "  31,\n",
              "  121,\n",
              "  122,\n",
              "  57,\n",
              "  1,\n",
              "  3,\n",
              "  123,\n",
              "  124,\n",
              "  8,\n",
              "  27,\n",
              "  125,\n",
              "  58],\n",
              " [1,\n",
              "  117,\n",
              "  10,\n",
              "  18,\n",
              "  118,\n",
              "  119,\n",
              "  47,\n",
              "  48,\n",
              "  43,\n",
              "  44,\n",
              "  120,\n",
              "  2,\n",
              "  31,\n",
              "  121,\n",
              "  122,\n",
              "  57,\n",
              "  1,\n",
              "  3,\n",
              "  123,\n",
              "  124,\n",
              "  8,\n",
              "  27,\n",
              "  125,\n",
              "  58,\n",
              "  5],\n",
              " [1,\n",
              "  117,\n",
              "  10,\n",
              "  18,\n",
              "  118,\n",
              "  119,\n",
              "  47,\n",
              "  48,\n",
              "  43,\n",
              "  44,\n",
              "  120,\n",
              "  2,\n",
              "  31,\n",
              "  121,\n",
              "  122,\n",
              "  57,\n",
              "  1,\n",
              "  3,\n",
              "  123,\n",
              "  124,\n",
              "  8,\n",
              "  27,\n",
              "  125,\n",
              "  58,\n",
              "  5,\n",
              "  126],\n",
              " [1,\n",
              "  117,\n",
              "  10,\n",
              "  18,\n",
              "  118,\n",
              "  119,\n",
              "  47,\n",
              "  48,\n",
              "  43,\n",
              "  44,\n",
              "  120,\n",
              "  2,\n",
              "  31,\n",
              "  121,\n",
              "  122,\n",
              "  57,\n",
              "  1,\n",
              "  3,\n",
              "  123,\n",
              "  124,\n",
              "  8,\n",
              "  27,\n",
              "  125,\n",
              "  58,\n",
              "  5,\n",
              "  126,\n",
              "  59],\n",
              " [11, 1],\n",
              " [11, 1, 127],\n",
              " [11, 1, 127, 30],\n",
              " [11, 1, 127, 30, 33],\n",
              " [11, 1, 127, 30, 33, 128],\n",
              " [11, 1, 127, 30, 33, 128, 129],\n",
              " [11, 1, 127, 30, 33, 128, 129, 5],\n",
              " [11, 1, 127, 30, 33, 128, 129, 5, 60],\n",
              " [61, 1],\n",
              " [61, 1, 3],\n",
              " [61, 1, 3, 35],\n",
              " [61, 1, 3, 35, 36],\n",
              " [61, 1, 3, 35, 36, 24],\n",
              " [61, 1, 3, 35, 36, 24, 34],\n",
              " [61, 1, 3, 35, 36, 24, 34, 2],\n",
              " [61, 1, 3, 35, 36, 24, 34, 2, 25],\n",
              " [61, 1, 3, 35, 36, 24, 34, 2, 25, 62],\n",
              " [61, 1, 3, 35, 36, 24, 34, 2, 25, 62, 63],\n",
              " [61, 1, 3, 35, 36, 24, 34, 2, 25, 62, 63, 5],\n",
              " [61, 1, 3, 35, 36, 24, 34, 2, 25, 62, 63, 5, 130],\n",
              " [61, 1, 3, 35, 36, 24, 34, 2, 25, 62, 63, 5, 130, 64],\n",
              " [61, 1, 3, 35, 36, 24, 34, 2, 25, 62, 63, 5, 130, 64, 131],\n",
              " [61, 1, 3, 35, 36, 24, 34, 2, 25, 62, 63, 5, 130, 64, 131, 132],\n",
              " [61, 1, 3, 35, 36, 24, 34, 2, 25, 62, 63, 5, 130, 64, 131, 132, 133],\n",
              " [61, 1, 3, 35, 36, 24, 34, 2, 25, 62, 63, 5, 130, 64, 131, 132, 133, 28],\n",
              " [61, 1, 3, 35, 36, 24, 34, 2, 25, 62, 63, 5, 130, 64, 131, 132, 133, 28, 134],\n",
              " [61,\n",
              "  1,\n",
              "  3,\n",
              "  35,\n",
              "  36,\n",
              "  24,\n",
              "  34,\n",
              "  2,\n",
              "  25,\n",
              "  62,\n",
              "  63,\n",
              "  5,\n",
              "  130,\n",
              "  64,\n",
              "  131,\n",
              "  132,\n",
              "  133,\n",
              "  28,\n",
              "  134,\n",
              "  2],\n",
              " [61,\n",
              "  1,\n",
              "  3,\n",
              "  35,\n",
              "  36,\n",
              "  24,\n",
              "  34,\n",
              "  2,\n",
              "  25,\n",
              "  62,\n",
              "  63,\n",
              "  5,\n",
              "  130,\n",
              "  64,\n",
              "  131,\n",
              "  132,\n",
              "  133,\n",
              "  28,\n",
              "  134,\n",
              "  2,\n",
              "  14],\n",
              " [61,\n",
              "  1,\n",
              "  3,\n",
              "  35,\n",
              "  36,\n",
              "  24,\n",
              "  34,\n",
              "  2,\n",
              "  25,\n",
              "  62,\n",
              "  63,\n",
              "  5,\n",
              "  130,\n",
              "  64,\n",
              "  131,\n",
              "  132,\n",
              "  133,\n",
              "  28,\n",
              "  134,\n",
              "  2,\n",
              "  14,\n",
              "  135],\n",
              " [61,\n",
              "  1,\n",
              "  3,\n",
              "  35,\n",
              "  36,\n",
              "  24,\n",
              "  34,\n",
              "  2,\n",
              "  25,\n",
              "  62,\n",
              "  63,\n",
              "  5,\n",
              "  130,\n",
              "  64,\n",
              "  131,\n",
              "  132,\n",
              "  133,\n",
              "  28,\n",
              "  134,\n",
              "  2,\n",
              "  14,\n",
              "  135,\n",
              "  4],\n",
              " [9, 41],\n",
              " [9, 41, 23],\n",
              " [9, 41, 23, 15],\n",
              " [9, 41, 23, 15, 136],\n",
              " [9, 41, 23, 15, 136, 137],\n",
              " [1, 3],\n",
              " [1, 3, 138],\n",
              " [1, 3, 138, 139],\n",
              " [1, 3, 138, 139, 15],\n",
              " [1, 3, 138, 139, 15, 49],\n",
              " [1, 3, 138, 139, 15, 49, 12],\n",
              " [1, 3, 138, 139, 15, 49, 12, 27],\n",
              " [1, 3, 138, 139, 15, 49, 12, 27, 65],\n",
              " [1, 3, 138, 139, 15, 49, 12, 27, 65, 140],\n",
              " [1, 3, 138, 139, 15, 49, 12, 27, 65, 140, 17],\n",
              " [1, 3, 138, 139, 15, 49, 12, 27, 65, 140, 17, 37],\n",
              " [1, 3, 138, 139, 15, 49, 12, 27, 65, 140, 17, 37, 2],\n",
              " [1, 3, 138, 139, 15, 49, 12, 27, 65, 140, 17, 37, 2, 14],\n",
              " [1, 3, 138, 139, 15, 49, 12, 27, 65, 140, 17, 37, 2, 14, 39],\n",
              " [1, 3, 138, 139, 15, 49, 12, 27, 65, 140, 17, 37, 2, 14, 39, 40],\n",
              " [1, 3, 138, 139, 15, 49, 12, 27, 65, 140, 17, 37, 2, 14, 39, 40, 4],\n",
              " [1, 3, 138, 139, 15, 49, 12, 27, 65, 140, 17, 37, 2, 14, 39, 40, 4, 53],\n",
              " [1, 3, 138, 139, 15, 49, 12, 27, 65, 140, 17, 37, 2, 14, 39, 40, 4, 53, 141],\n",
              " [1,\n",
              "  3,\n",
              "  138,\n",
              "  139,\n",
              "  15,\n",
              "  49,\n",
              "  12,\n",
              "  27,\n",
              "  65,\n",
              "  140,\n",
              "  17,\n",
              "  37,\n",
              "  2,\n",
              "  14,\n",
              "  39,\n",
              "  40,\n",
              "  4,\n",
              "  53,\n",
              "  141,\n",
              "  142],\n",
              " [1,\n",
              "  3,\n",
              "  138,\n",
              "  139,\n",
              "  15,\n",
              "  49,\n",
              "  12,\n",
              "  27,\n",
              "  65,\n",
              "  140,\n",
              "  17,\n",
              "  37,\n",
              "  2,\n",
              "  14,\n",
              "  39,\n",
              "  40,\n",
              "  4,\n",
              "  53,\n",
              "  141,\n",
              "  142,\n",
              "  50],\n",
              " [1,\n",
              "  3,\n",
              "  138,\n",
              "  139,\n",
              "  15,\n",
              "  49,\n",
              "  12,\n",
              "  27,\n",
              "  65,\n",
              "  140,\n",
              "  17,\n",
              "  37,\n",
              "  2,\n",
              "  14,\n",
              "  39,\n",
              "  40,\n",
              "  4,\n",
              "  53,\n",
              "  141,\n",
              "  142,\n",
              "  50,\n",
              "  143],\n",
              " [1,\n",
              "  3,\n",
              "  138,\n",
              "  139,\n",
              "  15,\n",
              "  49,\n",
              "  12,\n",
              "  27,\n",
              "  65,\n",
              "  140,\n",
              "  17,\n",
              "  37,\n",
              "  2,\n",
              "  14,\n",
              "  39,\n",
              "  40,\n",
              "  4,\n",
              "  53,\n",
              "  141,\n",
              "  142,\n",
              "  50,\n",
              "  143,\n",
              "  144],\n",
              " [1,\n",
              "  3,\n",
              "  138,\n",
              "  139,\n",
              "  15,\n",
              "  49,\n",
              "  12,\n",
              "  27,\n",
              "  65,\n",
              "  140,\n",
              "  17,\n",
              "  37,\n",
              "  2,\n",
              "  14,\n",
              "  39,\n",
              "  40,\n",
              "  4,\n",
              "  53,\n",
              "  141,\n",
              "  142,\n",
              "  50,\n",
              "  143,\n",
              "  144,\n",
              "  64],\n",
              " [1,\n",
              "  3,\n",
              "  138,\n",
              "  139,\n",
              "  15,\n",
              "  49,\n",
              "  12,\n",
              "  27,\n",
              "  65,\n",
              "  140,\n",
              "  17,\n",
              "  37,\n",
              "  2,\n",
              "  14,\n",
              "  39,\n",
              "  40,\n",
              "  4,\n",
              "  53,\n",
              "  141,\n",
              "  142,\n",
              "  50,\n",
              "  143,\n",
              "  144,\n",
              "  64,\n",
              "  145],\n",
              " [1,\n",
              "  3,\n",
              "  138,\n",
              "  139,\n",
              "  15,\n",
              "  49,\n",
              "  12,\n",
              "  27,\n",
              "  65,\n",
              "  140,\n",
              "  17,\n",
              "  37,\n",
              "  2,\n",
              "  14,\n",
              "  39,\n",
              "  40,\n",
              "  4,\n",
              "  53,\n",
              "  141,\n",
              "  142,\n",
              "  50,\n",
              "  143,\n",
              "  144,\n",
              "  64,\n",
              "  145,\n",
              "  146],\n",
              " [1,\n",
              "  3,\n",
              "  138,\n",
              "  139,\n",
              "  15,\n",
              "  49,\n",
              "  12,\n",
              "  27,\n",
              "  65,\n",
              "  140,\n",
              "  17,\n",
              "  37,\n",
              "  2,\n",
              "  14,\n",
              "  39,\n",
              "  40,\n",
              "  4,\n",
              "  53,\n",
              "  141,\n",
              "  142,\n",
              "  50,\n",
              "  143,\n",
              "  144,\n",
              "  64,\n",
              "  145,\n",
              "  146,\n",
              "  2],\n",
              " [1,\n",
              "  3,\n",
              "  138,\n",
              "  139,\n",
              "  15,\n",
              "  49,\n",
              "  12,\n",
              "  27,\n",
              "  65,\n",
              "  140,\n",
              "  17,\n",
              "  37,\n",
              "  2,\n",
              "  14,\n",
              "  39,\n",
              "  40,\n",
              "  4,\n",
              "  53,\n",
              "  141,\n",
              "  142,\n",
              "  50,\n",
              "  143,\n",
              "  144,\n",
              "  64,\n",
              "  145,\n",
              "  146,\n",
              "  2,\n",
              "  147],\n",
              " [1,\n",
              "  3,\n",
              "  138,\n",
              "  139,\n",
              "  15,\n",
              "  49,\n",
              "  12,\n",
              "  27,\n",
              "  65,\n",
              "  140,\n",
              "  17,\n",
              "  37,\n",
              "  2,\n",
              "  14,\n",
              "  39,\n",
              "  40,\n",
              "  4,\n",
              "  53,\n",
              "  141,\n",
              "  142,\n",
              "  50,\n",
              "  143,\n",
              "  144,\n",
              "  64,\n",
              "  145,\n",
              "  146,\n",
              "  2,\n",
              "  147,\n",
              "  8],\n",
              " [1,\n",
              "  3,\n",
              "  138,\n",
              "  139,\n",
              "  15,\n",
              "  49,\n",
              "  12,\n",
              "  27,\n",
              "  65,\n",
              "  140,\n",
              "  17,\n",
              "  37,\n",
              "  2,\n",
              "  14,\n",
              "  39,\n",
              "  40,\n",
              "  4,\n",
              "  53,\n",
              "  141,\n",
              "  142,\n",
              "  50,\n",
              "  143,\n",
              "  144,\n",
              "  64,\n",
              "  145,\n",
              "  146,\n",
              "  2,\n",
              "  147,\n",
              "  8,\n",
              "  7],\n",
              " [1,\n",
              "  3,\n",
              "  138,\n",
              "  139,\n",
              "  15,\n",
              "  49,\n",
              "  12,\n",
              "  27,\n",
              "  65,\n",
              "  140,\n",
              "  17,\n",
              "  37,\n",
              "  2,\n",
              "  14,\n",
              "  39,\n",
              "  40,\n",
              "  4,\n",
              "  53,\n",
              "  141,\n",
              "  142,\n",
              "  50,\n",
              "  143,\n",
              "  144,\n",
              "  64,\n",
              "  145,\n",
              "  146,\n",
              "  2,\n",
              "  147,\n",
              "  8,\n",
              "  7,\n",
              "  148],\n",
              " [9, 52],\n",
              " [9, 52, 16],\n",
              " [9, 52, 16, 149],\n",
              " [9, 52, 16, 149, 12],\n",
              " [9, 52, 16, 149, 12, 21],\n",
              " [9, 52, 16, 149, 12, 21, 150],\n",
              " [9, 52, 16, 149, 12, 21, 150, 29],\n",
              " [1, 151],\n",
              " [1, 151, 152],\n",
              " [1, 151, 152, 6],\n",
              " [1, 151, 152, 6, 153],\n",
              " [1, 151, 152, 6, 153, 2],\n",
              " [1, 151, 152, 6, 153, 2, 19],\n",
              " [1, 151, 152, 6, 153, 2, 19, 7],\n",
              " [1, 151, 152, 6, 153, 2, 19, 7, 154],\n",
              " [1, 151, 152, 6, 153, 2, 19, 7, 154, 1],\n",
              " [1, 151, 152, 6, 153, 2, 19, 7, 154, 1, 13],\n",
              " [1, 151, 152, 6, 153, 2, 19, 7, 154, 1, 13, 6],\n",
              " [1, 151, 152, 6, 153, 2, 19, 7, 154, 1, 13, 6, 155],\n",
              " [1, 151, 152, 6, 153, 2, 19, 7, 154, 1, 13, 6, 155, 63],\n",
              " [1, 151, 152, 6, 153, 2, 19, 7, 154, 1, 13, 6, 155, 63, 4],\n",
              " [1, 151, 152, 6, 153, 2, 19, 7, 154, 1, 13, 6, 155, 63, 4, 156],\n",
              " [1, 151, 152, 6, 153, 2, 19, 7, 154, 1, 13, 6, 155, 63, 4, 156, 157],\n",
              " [1, 151, 152, 6, 153, 2, 19, 7, 154, 1, 13, 6, 155, 63, 4, 156, 157, 26],\n",
              " [1, 151, 152, 6, 153, 2, 19, 7, 154, 1, 13, 6, 155, 63, 4, 156, 157, 26, 158],\n",
              " [1,\n",
              "  151,\n",
              "  152,\n",
              "  6,\n",
              "  153,\n",
              "  2,\n",
              "  19,\n",
              "  7,\n",
              "  154,\n",
              "  1,\n",
              "  13,\n",
              "  6,\n",
              "  155,\n",
              "  63,\n",
              "  4,\n",
              "  156,\n",
              "  157,\n",
              "  26,\n",
              "  158,\n",
              "  54],\n",
              " [1,\n",
              "  151,\n",
              "  152,\n",
              "  6,\n",
              "  153,\n",
              "  2,\n",
              "  19,\n",
              "  7,\n",
              "  154,\n",
              "  1,\n",
              "  13,\n",
              "  6,\n",
              "  155,\n",
              "  63,\n",
              "  4,\n",
              "  156,\n",
              "  157,\n",
              "  26,\n",
              "  158,\n",
              "  54,\n",
              "  55],\n",
              " [1,\n",
              "  151,\n",
              "  152,\n",
              "  6,\n",
              "  153,\n",
              "  2,\n",
              "  19,\n",
              "  7,\n",
              "  154,\n",
              "  1,\n",
              "  13,\n",
              "  6,\n",
              "  155,\n",
              "  63,\n",
              "  4,\n",
              "  156,\n",
              "  157,\n",
              "  26,\n",
              "  158,\n",
              "  54,\n",
              "  55,\n",
              "  159],\n",
              " [1,\n",
              "  151,\n",
              "  152,\n",
              "  6,\n",
              "  153,\n",
              "  2,\n",
              "  19,\n",
              "  7,\n",
              "  154,\n",
              "  1,\n",
              "  13,\n",
              "  6,\n",
              "  155,\n",
              "  63,\n",
              "  4,\n",
              "  156,\n",
              "  157,\n",
              "  26,\n",
              "  158,\n",
              "  54,\n",
              "  55,\n",
              "  159,\n",
              "  160],\n",
              " [1,\n",
              "  151,\n",
              "  152,\n",
              "  6,\n",
              "  153,\n",
              "  2,\n",
              "  19,\n",
              "  7,\n",
              "  154,\n",
              "  1,\n",
              "  13,\n",
              "  6,\n",
              "  155,\n",
              "  63,\n",
              "  4,\n",
              "  156,\n",
              "  157,\n",
              "  26,\n",
              "  158,\n",
              "  54,\n",
              "  55,\n",
              "  159,\n",
              "  160,\n",
              "  12],\n",
              " [1,\n",
              "  151,\n",
              "  152,\n",
              "  6,\n",
              "  153,\n",
              "  2,\n",
              "  19,\n",
              "  7,\n",
              "  154,\n",
              "  1,\n",
              "  13,\n",
              "  6,\n",
              "  155,\n",
              "  63,\n",
              "  4,\n",
              "  156,\n",
              "  157,\n",
              "  26,\n",
              "  158,\n",
              "  54,\n",
              "  55,\n",
              "  159,\n",
              "  160,\n",
              "  12,\n",
              "  161],\n",
              " [1,\n",
              "  151,\n",
              "  152,\n",
              "  6,\n",
              "  153,\n",
              "  2,\n",
              "  19,\n",
              "  7,\n",
              "  154,\n",
              "  1,\n",
              "  13,\n",
              "  6,\n",
              "  155,\n",
              "  63,\n",
              "  4,\n",
              "  156,\n",
              "  157,\n",
              "  26,\n",
              "  158,\n",
              "  54,\n",
              "  55,\n",
              "  159,\n",
              "  160,\n",
              "  12,\n",
              "  161,\n",
              "  51],\n",
              " [1,\n",
              "  151,\n",
              "  152,\n",
              "  6,\n",
              "  153,\n",
              "  2,\n",
              "  19,\n",
              "  7,\n",
              "  154,\n",
              "  1,\n",
              "  13,\n",
              "  6,\n",
              "  155,\n",
              "  63,\n",
              "  4,\n",
              "  156,\n",
              "  157,\n",
              "  26,\n",
              "  158,\n",
              "  54,\n",
              "  55,\n",
              "  159,\n",
              "  160,\n",
              "  12,\n",
              "  161,\n",
              "  51,\n",
              "  56],\n",
              " [1,\n",
              "  151,\n",
              "  152,\n",
              "  6,\n",
              "  153,\n",
              "  2,\n",
              "  19,\n",
              "  7,\n",
              "  154,\n",
              "  1,\n",
              "  13,\n",
              "  6,\n",
              "  155,\n",
              "  63,\n",
              "  4,\n",
              "  156,\n",
              "  157,\n",
              "  26,\n",
              "  158,\n",
              "  54,\n",
              "  55,\n",
              "  159,\n",
              "  160,\n",
              "  12,\n",
              "  161,\n",
              "  51,\n",
              "  56,\n",
              "  162],\n",
              " [11, 1],\n",
              " [11, 1, 10],\n",
              " [11, 1, 10, 6],\n",
              " [11, 1, 10, 6, 66],\n",
              " [11, 1, 10, 6, 66, 4],\n",
              " [61, 1],\n",
              " [61, 1, 3],\n",
              " [61, 1, 3, 67],\n",
              " [61, 1, 3, 67, 8],\n",
              " [61, 1, 3, 67, 8, 163],\n",
              " [61, 1, 3, 67, 8, 163, 65],\n",
              " [61, 1, 3, 67, 8, 163, 65, 58],\n",
              " [61, 1, 3, 67, 8, 163, 65, 58, 5],\n",
              " [61, 1, 3, 67, 8, 163, 65, 58, 5, 45],\n",
              " [61, 1, 3, 67, 8, 163, 65, 58, 5, 45, 164],\n",
              " [61, 1, 3, 67, 8, 163, 65, 58, 5, 45, 164, 17],\n",
              " [61, 1, 3, 67, 8, 163, 65, 58, 5, 45, 164, 17, 165],\n",
              " [61, 1, 3, 67, 8, 163, 65, 58, 5, 45, 164, 17, 165, 166],\n",
              " [61, 1, 3, 67, 8, 163, 65, 58, 5, 45, 164, 17, 165, 166, 46],\n",
              " [61, 1, 3, 67, 8, 163, 65, 58, 5, 45, 164, 17, 165, 166, 46, 167],\n",
              " [61, 1, 3, 67, 8, 163, 65, 58, 5, 45, 164, 17, 165, 166, 46, 167, 2],\n",
              " [61, 1, 3, 67, 8, 163, 65, 58, 5, 45, 164, 17, 165, 166, 46, 167, 2, 168],\n",
              " [61, 1, 3, 67, 8, 163, 65, 58, 5, 45, 164, 17, 165, 166, 46, 167, 2, 168, 66],\n",
              " [61,\n",
              "  1,\n",
              "  3,\n",
              "  67,\n",
              "  8,\n",
              "  163,\n",
              "  65,\n",
              "  58,\n",
              "  5,\n",
              "  45,\n",
              "  164,\n",
              "  17,\n",
              "  165,\n",
              "  166,\n",
              "  46,\n",
              "  167,\n",
              "  2,\n",
              "  168,\n",
              "  66,\n",
              "  42],\n",
              " [61,\n",
              "  1,\n",
              "  3,\n",
              "  67,\n",
              "  8,\n",
              "  163,\n",
              "  65,\n",
              "  58,\n",
              "  5,\n",
              "  45,\n",
              "  164,\n",
              "  17,\n",
              "  165,\n",
              "  166,\n",
              "  46,\n",
              "  167,\n",
              "  2,\n",
              "  168,\n",
              "  66,\n",
              "  42,\n",
              "  57],\n",
              " [3, 1],\n",
              " [3, 1, 67],\n",
              " [3, 1, 67, 8],\n",
              " [3, 1, 67, 8, 169],\n",
              " [3, 1, 67, 8, 169, 170],\n",
              " [3, 1, 67, 8, 169, 170, 29],\n",
              " [171, 1],\n",
              " [171, 1, 3],\n",
              " [171, 1, 3, 172],\n",
              " [171, 1, 3, 172, 6],\n",
              " [171, 1, 3, 172, 6, 62],\n",
              " [171, 1, 3, 172, 6, 62, 173],\n",
              " [171, 1, 3, 172, 6, 62, 173, 5],\n",
              " [171, 1, 3, 172, 6, 62, 173, 5, 60],\n",
              " [171, 1, 3, 172, 6, 62, 173, 5, 60, 174],\n",
              " [171, 1, 3, 172, 6, 62, 173, 5, 60, 174, 175],\n",
              " [171, 1, 3, 172, 6, 62, 173, 5, 60, 174, 175, 176],\n",
              " [171, 1, 3, 172, 6, 62, 173, 5, 60, 174, 175, 176, 14],\n",
              " [171, 1, 3, 172, 6, 62, 173, 5, 60, 174, 175, 176, 14, 24],\n",
              " [171, 1, 3, 172, 6, 62, 173, 5, 60, 174, 175, 176, 14, 24, 28],\n",
              " [171, 1, 3, 172, 6, 62, 173, 5, 60, 174, 175, 176, 14, 24, 28, 2],\n",
              " [171, 1, 3, 172, 6, 62, 173, 5, 60, 174, 175, 176, 14, 24, 28, 2, 7],\n",
              " [171, 1, 3, 172, 6, 62, 173, 5, 60, 174, 175, 176, 14, 24, 28, 2, 7, 38],\n",
              " [171, 1, 3, 172, 6, 62, 173, 5, 60, 174, 175, 176, 14, 24, 28, 2, 7, 38, 5],\n",
              " [171,\n",
              "  1,\n",
              "  3,\n",
              "  172,\n",
              "  6,\n",
              "  62,\n",
              "  173,\n",
              "  5,\n",
              "  60,\n",
              "  174,\n",
              "  175,\n",
              "  176,\n",
              "  14,\n",
              "  24,\n",
              "  28,\n",
              "  2,\n",
              "  7,\n",
              "  38,\n",
              "  5,\n",
              "  177],\n",
              " [171,\n",
              "  1,\n",
              "  3,\n",
              "  172,\n",
              "  6,\n",
              "  62,\n",
              "  173,\n",
              "  5,\n",
              "  60,\n",
              "  174,\n",
              "  175,\n",
              "  176,\n",
              "  14,\n",
              "  24,\n",
              "  28,\n",
              "  2,\n",
              "  7,\n",
              "  38,\n",
              "  5,\n",
              "  177,\n",
              "  59]]"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "CrzbvUUQCXPU"
      },
      "outputs": [],
      "source": [
        "max_len = max([len(x) for x in input_sequences])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "9oPMoWBSD1_U"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "padded_input_sequences = pad_sequences(input_sequences, maxlen = max_len, padding='pre')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miRb-QZyIi7_",
        "outputId": "e1d10078-2877-40eb-aebd-f5a74656d0b3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[  0,   0,   0, ...,   0,  68,   3],\n",
              "       [  0,   0,   0, ...,  68,   3,   1],\n",
              "       [  0,   0,   0, ...,   0,   1,   3],\n",
              "       ...,\n",
              "       [  0,   0,   0, ...,   7,  38,   5],\n",
              "       [  0,   0,   0, ...,  38,   5, 177],\n",
              "       [  0,   0,   0, ...,   5, 177,  59]], dtype=int32)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "padded_input_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "qVI0-UUrIsd3"
      },
      "outputs": [],
      "source": [
        "X = padded_input_sequences[:,:-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "lXrYHTDFI3uE"
      },
      "outputs": [],
      "source": [
        "y = padded_input_sequences[:,-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmsFnHx1Qdow",
        "outputId": "726091f2-6d5e-408e-aa32-fafa30583879"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(320, 37)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wyYqYgZSeck",
        "outputId": "87e67e59-511d-4803-c1d8-383fdbd9dea7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(320,)"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "rs1NPitwSgzk"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y = to_categorical(y,num_classes=283)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQMJ0I6xSiZf",
        "outputId": "c5a0bfee-e63f-4d04-fdc0-d9a64c314804"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(320, 283)"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "9kVeTvR2S8Fk"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wo-OYfHpTK2o",
        "outputId": "a135eea2-37b4-4427-ca78-79c9af481c1f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Define model\n",
        "model = Sequential()\n",
        "# Embedding layer first (input_length = 37, input_dim = 283 tokens, output_dim = 100 features per token)\n",
        "model.add(Embedding(input_dim=283, output_dim=100, input_length=37))\n",
        "# Stacked LSTM layers\n",
        "model.add(LSTM(150, return_sequences=True))\n",
        "model.add(LSTM(150, return_sequences=True))\n",
        "model.add(LSTM(150))\n",
        "# Output layer (softmax over 283 classes/tokens)\n",
        "model.add(Dense(283, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "-GGjqh7ue_Yq"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "OxxXkrSXfIBv",
        "outputId": "0d0979ee-4238-4b1b-bb03-d60f5a489a64"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "LpFUCALCfJRR",
        "outputId": "323951e5-9773-4c2d-d185-9837e33ca4d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.0219 - loss: 5.6306 \n",
            "Epoch 2/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0424 - loss: 5.2839\n",
            "Epoch 3/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0427 - loss: 5.0274  \n",
            "Epoch 4/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0560 - loss: 4.9956\n",
            "Epoch 5/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0439 - loss: 4.9093\n",
            "Epoch 6/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0586 - loss: 4.8147\n",
            "Epoch 7/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0855 - loss: 4.7002\n",
            "Epoch 8/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0712 - loss: 4.6442\n",
            "Epoch 9/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0733 - loss: 4.5050\n",
            "Epoch 10/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0668 - loss: 4.5037\n",
            "Epoch 11/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0774 - loss: 4.4419\n",
            "Epoch 12/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0576 - loss: 4.4369\n",
            "Epoch 13/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0749 - loss: 4.3023\n",
            "Epoch 14/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0788 - loss: 4.2429\n",
            "Epoch 15/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0561 - loss: 4.3079    \n",
            "Epoch 16/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0968 - loss: 4.1600\n",
            "Epoch 17/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0889 - loss: 4.1481\n",
            "Epoch 18/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0776 - loss: 4.0787\n",
            "Epoch 19/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0768 - loss: 4.0174\n",
            "Epoch 20/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0676 - loss: 4.0204\n",
            "Epoch 21/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0814 - loss: 3.9802\n",
            "Epoch 22/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1056 - loss: 3.9060\n",
            "Epoch 23/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1146 - loss: 3.8450\n",
            "Epoch 24/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1169 - loss: 3.8401\n",
            "Epoch 25/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.1168 - loss: 3.7500\n",
            "Epoch 26/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0979 - loss: 3.7949\n",
            "Epoch 27/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.1327 - loss: 3.6752\n",
            "Epoch 28/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.1260 - loss: 3.6241\n",
            "Epoch 29/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.1176 - loss: 3.5772\n",
            "Epoch 30/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.1200 - loss: 3.5898\n",
            "Epoch 31/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.1177 - loss: 3.5194\n",
            "Epoch 32/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.1497 - loss: 3.4343\n",
            "Epoch 33/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1540 - loss: 3.4342\n",
            "Epoch 34/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1784 - loss: 3.3753\n",
            "Epoch 35/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1560 - loss: 3.3659\n",
            "Epoch 36/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1266 - loss: 3.3545\n",
            "Epoch 37/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1885 - loss: 3.2889\n",
            "Epoch 38/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1835 - loss: 3.2386\n",
            "Epoch 39/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1721 - loss: 3.2052\n",
            "Epoch 40/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1772 - loss: 3.1935\n",
            "Epoch 41/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1784 - loss: 3.1779\n",
            "Epoch 42/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2217 - loss: 3.1141\n",
            "Epoch 43/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2242 - loss: 3.0108\n",
            "Epoch 44/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.2176 - loss: 3.0285\n",
            "Epoch 45/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2229 - loss: 3.0165\n",
            "Epoch 46/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2035 - loss: 2.9939\n",
            "Epoch 47/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2735 - loss: 2.8861\n",
            "Epoch 48/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2643 - loss: 2.9045\n",
            "Epoch 49/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2826 - loss: 2.8402\n",
            "Epoch 50/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2690 - loss: 2.8088\n",
            "Epoch 51/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2831 - loss: 2.8200\n",
            "Epoch 52/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3116 - loss: 2.7128\n",
            "Epoch 53/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3423 - loss: 2.6586\n",
            "Epoch 54/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3057 - loss: 2.6738\n",
            "Epoch 55/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3196 - loss: 2.6359\n",
            "Epoch 56/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3634 - loss: 2.5768\n",
            "Epoch 57/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3795 - loss: 2.5534\n",
            "Epoch 58/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3891 - loss: 2.4917\n",
            "Epoch 59/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3891 - loss: 2.4796\n",
            "Epoch 60/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3738 - loss: 2.4900\n",
            "Epoch 61/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3793 - loss: 2.4811\n",
            "Epoch 62/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3973 - loss: 2.4151\n",
            "Epoch 63/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3775 - loss: 2.4029\n",
            "Epoch 64/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4077 - loss: 2.3226\n",
            "Epoch 65/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4723 - loss: 2.2773\n",
            "Epoch 66/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4565 - loss: 2.2859\n",
            "Epoch 67/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4486 - loss: 2.2703\n",
            "Epoch 68/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4862 - loss: 2.2159\n",
            "Epoch 69/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5047 - loss: 2.1953\n",
            "Epoch 70/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5036 - loss: 2.1579\n",
            "Epoch 71/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5042 - loss: 2.1517\n",
            "Epoch 72/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5737 - loss: 2.0450\n",
            "Epoch 73/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5355 - loss: 2.0738\n",
            "Epoch 74/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5665 - loss: 2.0532\n",
            "Epoch 75/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5294 - loss: 2.0696\n",
            "Epoch 76/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5494 - loss: 2.0271\n",
            "Epoch 77/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5803 - loss: 1.9850\n",
            "Epoch 78/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5851 - loss: 1.9634\n",
            "Epoch 79/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6070 - loss: 1.8982\n",
            "Epoch 80/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5276 - loss: 1.9770\n",
            "Epoch 81/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5433 - loss: 1.9637\n",
            "Epoch 82/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5554 - loss: 1.9097\n",
            "Epoch 83/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6578 - loss: 1.7810\n",
            "Epoch 84/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6392 - loss: 1.8370\n",
            "Epoch 85/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6252 - loss: 1.7165\n",
            "Epoch 86/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6152 - loss: 1.7662\n",
            "Epoch 87/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6208 - loss: 1.7909\n",
            "Epoch 88/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6812 - loss: 1.6971\n",
            "Epoch 89/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6809 - loss: 1.6819\n",
            "Epoch 90/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6410 - loss: 1.7031\n",
            "Epoch 91/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6707 - loss: 1.6423\n",
            "Epoch 92/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6919 - loss: 1.6340\n",
            "Epoch 93/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7044 - loss: 1.6529\n",
            "Epoch 94/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7241 - loss: 1.5756\n",
            "Epoch 95/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6558 - loss: 1.6350\n",
            "Epoch 96/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6933 - loss: 1.5749\n",
            "Epoch 97/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6831 - loss: 1.5592\n",
            "Epoch 98/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7581 - loss: 1.4983\n",
            "Epoch 99/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7366 - loss: 1.4772\n",
            "Epoch 100/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7328 - loss: 1.5376\n",
            "Epoch 101/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7245 - loss: 1.4756\n",
            "Epoch 102/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7603 - loss: 1.4399\n",
            "Epoch 103/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7272 - loss: 1.4135\n",
            "Epoch 104/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7601 - loss: 1.4142\n",
            "Epoch 105/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7565 - loss: 1.3683\n",
            "Epoch 106/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7986 - loss: 1.2792\n",
            "Epoch 107/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8110 - loss: 1.3002\n",
            "Epoch 108/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8442 - loss: 1.2503\n",
            "Epoch 109/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8098 - loss: 1.3026\n",
            "Epoch 110/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8127 - loss: 1.2470\n",
            "Epoch 111/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8442 - loss: 1.1950\n",
            "Epoch 112/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8213 - loss: 1.2200\n",
            "Epoch 113/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8143 - loss: 1.2189\n",
            "Epoch 114/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8329 - loss: 1.1596\n",
            "Epoch 115/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8354 - loss: 1.1919\n",
            "Epoch 116/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8285 - loss: 1.1826\n",
            "Epoch 117/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8623 - loss: 1.1114\n",
            "Epoch 118/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8108 - loss: 1.1836\n",
            "Epoch 119/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8509 - loss: 1.1262\n",
            "Epoch 120/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8141 - loss: 1.1559\n",
            "Epoch 121/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8408 - loss: 1.0770\n",
            "Epoch 122/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8416 - loss: 1.0963\n",
            "Epoch 123/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8464 - loss: 1.0608\n",
            "Epoch 124/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8426 - loss: 1.0297\n",
            "Epoch 125/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8532 - loss: 1.0346\n",
            "Epoch 126/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8589 - loss: 0.9975\n",
            "Epoch 127/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8539 - loss: 1.0169\n",
            "Epoch 128/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8761 - loss: 0.9736\n",
            "Epoch 129/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8707 - loss: 0.9163\n",
            "Epoch 130/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8735 - loss: 0.9079\n",
            "Epoch 131/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9043 - loss: 0.8772\n",
            "Epoch 132/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9049 - loss: 0.8585\n",
            "Epoch 133/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8628 - loss: 0.8925\n",
            "Epoch 134/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8784 - loss: 0.9125\n",
            "Epoch 135/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8871 - loss: 0.9062\n",
            "Epoch 136/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8785 - loss: 0.8459\n",
            "Epoch 137/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8723 - loss: 0.8930\n",
            "Epoch 138/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8952 - loss: 0.8267\n",
            "Epoch 139/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9173 - loss: 0.8132\n",
            "Epoch 140/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8931 - loss: 0.7970\n",
            "Epoch 141/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9215 - loss: 0.7531\n",
            "Epoch 142/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9136 - loss: 0.7575\n",
            "Epoch 143/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9106 - loss: 0.7416\n",
            "Epoch 144/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9348 - loss: 0.7092\n",
            "Epoch 145/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8986 - loss: 0.7560\n",
            "Epoch 146/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9055 - loss: 0.7176\n",
            "Epoch 147/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8800 - loss: 0.7846\n",
            "Epoch 148/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8675 - loss: 0.8395\n",
            "Epoch 149/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7816 - loss: 0.9581\n",
            "Epoch 150/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8734 - loss: 0.8714\n",
            "Epoch 151/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8851 - loss: 0.8086\n",
            "Epoch 152/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9323 - loss: 0.7241\n",
            "Epoch 153/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9117 - loss: 0.7095\n",
            "Epoch 154/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8940 - loss: 0.7117\n",
            "Epoch 155/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9104 - loss: 0.6639\n",
            "Epoch 156/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9035 - loss: 0.6576\n",
            "Epoch 157/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9431 - loss: 0.5780\n",
            "Epoch 158/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9219 - loss: 0.5849\n",
            "Epoch 159/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9273 - loss: 0.6175\n",
            "Epoch 160/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9363 - loss: 0.5814\n",
            "Epoch 161/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9218 - loss: 0.5619\n",
            "Epoch 162/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9238 - loss: 0.5374\n",
            "Epoch 163/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9107 - loss: 0.5836\n",
            "Epoch 164/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9339 - loss: 0.5090\n",
            "Epoch 165/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9122 - loss: 0.5723\n",
            "Epoch 166/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9462 - loss: 0.4994\n",
            "Epoch 167/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9281 - loss: 0.5224\n",
            "Epoch 168/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9378 - loss: 0.5306\n",
            "Epoch 169/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9307 - loss: 0.4915\n",
            "Epoch 170/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9327 - loss: 0.5146\n",
            "Epoch 171/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9124 - loss: 0.5250\n",
            "Epoch 172/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9312 - loss: 0.5252\n",
            "Epoch 173/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9280 - loss: 0.4928\n",
            "Epoch 174/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9332 - loss: 0.4752\n",
            "Epoch 175/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9333 - loss: 0.4787\n",
            "Epoch 176/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9472 - loss: 0.4435\n",
            "Epoch 177/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9395 - loss: 0.4105\n",
            "Epoch 178/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9537 - loss: 0.3890\n",
            "Epoch 179/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9397 - loss: 0.4255\n",
            "Epoch 180/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9515 - loss: 0.4295\n",
            "Epoch 181/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9344 - loss: 0.4316\n",
            "Epoch 182/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9416 - loss: 0.4074\n",
            "Epoch 183/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9381 - loss: 0.4145\n",
            "Epoch 184/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9417 - loss: 0.4084\n",
            "Epoch 185/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9302 - loss: 0.3943\n",
            "Epoch 186/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9295 - loss: 0.4058\n",
            "Epoch 187/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9292 - loss: 0.4034\n",
            "Epoch 188/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9484 - loss: 0.3786\n",
            "Epoch 189/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9412 - loss: 0.3829\n",
            "Epoch 190/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9518 - loss: 0.3540\n",
            "Epoch 191/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9352 - loss: 0.3741\n",
            "Epoch 192/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9385 - loss: 0.3524\n",
            "Epoch 193/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9587 - loss: 0.3391\n",
            "Epoch 194/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9292 - loss: 0.3644\n",
            "Epoch 195/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9448 - loss: 0.3710\n",
            "Epoch 196/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9498 - loss: 0.3494\n",
            "Epoch 197/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9491 - loss: 0.3470\n",
            "Epoch 198/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9447 - loss: 0.3618\n",
            "Epoch 199/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9361 - loss: 0.3607\n",
            "Epoch 200/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9563 - loss: 0.3339\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7873ac4ffbc0>"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train the model\n",
        "model.fit(X, y, epochs=200)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGeYGwCMfTus",
        "outputId": "2d508555-b83e-470e-e7e5-1b5c10cce70b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Yes. I am passionate about Game Development and\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "Yes. I am passionate about Game Development and enjoy\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "Yes. I am passionate about Game Development and enjoy exploring\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "Yes. I am passionate about Game Development and enjoy exploring how\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "Yes. I am passionate about Game Development and enjoy exploring how ai\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "Yes. I am passionate about Game Development and enjoy exploring how ai can\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "Yes. I am passionate about Game Development and enjoy exploring how ai can can\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "Yes. I am passionate about Game Development and enjoy exploring how ai can can retrieval\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "Yes. I am passionate about Game Development and enjoy exploring how ai can can retrieval augmented\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "Yes. I am passionate about Game Development and enjoy exploring how ai can can retrieval augmented generation\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "text = \"Yes. I am passionate about Game Development\"\n",
        "\n",
        "for i in range(10):\n",
        "  # tokenize\n",
        "  token_text = tokenizer.texts_to_sequences([text])[0]\n",
        "  # padding\n",
        "  padded_token_text = pad_sequences([token_text], maxlen=56, padding='pre')\n",
        "  # predict\n",
        "  pos = np.argmax(model.predict(padded_token_text))\n",
        "\n",
        "  for word,index in tokenizer.word_index.items():\n",
        "    if index == pos:\n",
        "      text = text + \" \" + word\n",
        "      print(text)\n",
        "      time.sleep(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTxsj-_CjbQW",
        "outputId": "7e8e0b43-d8f5-4e87-8caf-33806965ab3a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'i': 1,\n",
              " 'and': 2,\n",
              " 'am': 3,\n",
              " 'systems': 4,\n",
              " 'ai': 5,\n",
              " 'on': 6,\n",
              " 'real': 7,\n",
              " 'in': 8,\n",
              " 'what': 9,\n",
              " 'work': 10,\n",
              " 'do': 11,\n",
              " 'to': 12,\n",
              " 'focus': 13,\n",
              " 'intelligent': 14,\n",
              " 'problems': 15,\n",
              " 'my': 16,\n",
              " 'retrieval': 17,\n",
              " 'with': 18,\n",
              " 'building': 19,\n",
              " 'that': 20,\n",
              " 'learning': 21,\n",
              " 'engineering': 22,\n",
              " 'of': 23,\n",
              " 'game': 24,\n",
              " 'enjoy': 25,\n",
              " 'production': 26,\n",
              " 'system': 27,\n",
              " 'environments': 28,\n",
              " 'technologies': 29,\n",
              " 'an': 30,\n",
              " 'modern': 31,\n",
              " 'machine': 32,\n",
              " 'interest': 33,\n",
              " 'development': 34,\n",
              " 'passionate': 35,\n",
              " 'about': 36,\n",
              " 'automation': 37,\n",
              " 'time': 38,\n",
              " 'decision': 39,\n",
              " 'making': 40,\n",
              " 'kind': 41,\n",
              " 'backend': 42,\n",
              " 'such': 43,\n",
              " 'as': 44,\n",
              " 'pipelines': 45,\n",
              " 'embedding': 46,\n",
              " 'vector': 47,\n",
              " 'databases': 48,\n",
              " 'related': 49,\n",
              " 'model': 50,\n",
              " 'or': 51,\n",
              " 'is': 52,\n",
              " '—': 53,\n",
              " 'rather': 54,\n",
              " 'than': 55,\n",
              " 'theoretical': 56,\n",
              " 'architectures': 57,\n",
              " 'for': 58,\n",
              " 'platforms': 59,\n",
              " 'applications': 60,\n",
              " 'yes': 61,\n",
              " 'exploring': 62,\n",
              " 'how': 63,\n",
              " 'be': 64,\n",
              " 'performance': 65,\n",
              " 'scalable': 66,\n",
              " 'interested': 67,\n",
              " 'who': 68,\n",
              " 'engineer': 69,\n",
              " 'a': 70,\n",
              " 'strong': 71,\n",
              " 'solve': 72,\n",
              " 'world': 73,\n",
              " 'using': 74,\n",
              " 'software': 75,\n",
              " 'practices': 76,\n",
              " 'are': 77,\n",
              " 'primary': 78,\n",
              " 'areas': 79,\n",
              " 'key': 80,\n",
              " 'interests': 81,\n",
              " 'lie': 82,\n",
              " 'artificial': 83,\n",
              " 'intelligence': 84,\n",
              " 'particularly': 85,\n",
              " 'designing': 86,\n",
              " 'combine': 87,\n",
              " 'reasoning': 88,\n",
              " 'doing': 89,\n",
              " 'the': 90,\n",
              " 'most': 91,\n",
              " 'working': 92,\n",
              " 'infrastructure': 93,\n",
              " 'augmented': 94,\n",
              " 'generation': 95,\n",
              " 'rag': 96,\n",
              " 'ready': 97,\n",
              " 'ml': 98,\n",
              " 'deployments': 99,\n",
              " 'like': 100,\n",
              " 'solving': 101,\n",
              " 'reliability': 102,\n",
              " 'hallucination': 103,\n",
              " 'mitigation': 104,\n",
              " 'optimization': 105,\n",
              " 'scalability': 106,\n",
              " 'more': 107,\n",
              " 'research': 108,\n",
              " 'primarily': 109,\n",
              " 'applied': 110,\n",
              " 'grade': 111,\n",
              " 'actually': 112,\n",
              " 'staying': 113,\n",
              " 'limited': 114,\n",
              " 'implementations': 115,\n",
              " 'typically': 116,\n",
              " 'frequently': 117,\n",
              " 'fastapi': 118,\n",
              " 'postgresql': 119,\n",
              " 'pgvector': 120,\n",
              " 'llm': 121,\n",
              " 'based': 122,\n",
              " 'also': 123,\n",
              " 'involved': 124,\n",
              " 'design': 125,\n",
              " 'driven': 126,\n",
              " 'have': 127,\n",
              " 'outside': 128,\n",
              " 'traditional': 129,\n",
              " 'can': 130,\n",
              " 'integrated': 131,\n",
              " 'into': 132,\n",
              " 'interactive': 133,\n",
              " 'simulations': 134,\n",
              " 'gameplay': 135,\n",
              " 'motivate': 136,\n",
              " 'me': 137,\n",
              " 'motivated': 138,\n",
              " 'by': 139,\n",
              " 'information': 140,\n",
              " 'especially': 141,\n",
              " 'where': 142,\n",
              " 'outputs': 143,\n",
              " 'must': 144,\n",
              " 'accurate': 145,\n",
              " 'explainable': 146,\n",
              " 'grounded': 147,\n",
              " 'data': 148,\n",
              " 'approach': 149,\n",
              " 'new': 150,\n",
              " 'prefer': 151,\n",
              " 'hands': 152,\n",
              " 'experimentation': 153,\n",
              " 'projects': 154,\n",
              " 'understanding': 155,\n",
              " 'behave': 156,\n",
              " 'under': 157,\n",
              " 'constraints': 158,\n",
              " 'limiting': 159,\n",
              " 'myself': 160,\n",
              " 'tutorials': 161,\n",
              " 'study': 162,\n",
              " 'optimizing': 163,\n",
              " 'improving': 164,\n",
              " 'latency': 165,\n",
              " 'handling': 166,\n",
              " 'mismatches': 167,\n",
              " 'deploying': 168,\n",
              " 'future': 169,\n",
              " 'oriented': 170,\n",
              " 'absolutely': 171,\n",
              " 'keen': 172,\n",
              " 'advanced': 173,\n",
              " 'including': 174,\n",
              " 'autonomous': 175,\n",
              " 'agents': 176,\n",
              " 'assisted': 177}"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.word_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92y7gE6pj9EZ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
